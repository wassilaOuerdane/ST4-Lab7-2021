{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5C2za_H4hdJW"
   },
   "source": [
    "<center><img src='https://drive.google.com/uc?export=view&id=1qJ8NqAZolTBQY7lN-deZ8xEsU3dlUiLz' width=200></center>\n",
    "\n",
    "\n",
    "<h6><center></center></h6>\n",
    "\n",
    "<h1>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "<center>Recherche d'Information et traitement de données massives </center>\n",
    "    <center> Lab 7 : Personnalisation : Systèmes de recommandation </center>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hh-yuZxVhdJZ"
   },
   "source": [
    "Ce LAB a pour objectif de vous familiariser avec le problème de la recommandation par la mise en place de la chaîne de traitements pour la réalisation d'un système de recommandation de films.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbefJYBUr8OZ"
   },
   "source": [
    "## Avant de démarrer\n",
    "\n",
    "Dans ce lab nous allons utiliser la bibliothèque Pandas. Pour la découvir (si ce n'est pas déjà fait), nous vous proposons un petit tuto que vous pouvez récupérer [ici](https://github.com/wassilaOuerdane/Lab7_TutoPanda_2021.git)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwOQ58Nxr8OZ"
   },
   "source": [
    "## Démarrage du Lab7\n",
    "\n",
    "Comme pour les précédents labs, pour le cas du lab effectué sur colab, voici les **instructions pour permettre l'importation du dossier Data fournie avec ce lab :**\n",
    "\n",
    "1.   Dans le dossier Lab7_Recom-2021 téléchargé depuis git, vous trouverez une archive Archive_Lab7.zip.\n",
    "2.   Ouvrir le panneau Fichiers de colab (c'est à dire cliquez sur le logo en forme de dossier à gauche) et cliquez sur le premier bouton en haut à gauche vous permettant de télécharger. Téléchargez ainsi l'Archive_Lab7.zip dans votre colab. Si besoin actualiser jusqu'à voir l'archive apparaître dans le panneau. \n",
    "3.    Exécutez la céllule de code suivante pour déziper l'archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YARbuhRVr8Oa"
   },
   "outputs": [],
   "source": [
    "!unzip Archive_Lab7.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGlCzY7ihdJa"
   },
   "source": [
    "### Avant propos : un bref rappel du Filtrage Collaboratif\n",
    "\n",
    "Le problème de la recommandation vise à prédire des scores de pertinence personnalisés à l’utilisateur pour un item, objet non vu. Différentes approches existent : filtrage collaboratif, basées sur le contenu, basées sur la connaissances, ...  (voir le cours 7)\n",
    "\n",
    "Dans ce Lab on s'intéressera au Filtrage collaboratif. L'idée est de prendre en compte les relations de similarité entre les utilisateurs et les éléments. En d'autres termes, la similarité entre éléments est déterminée en prenant en\n",
    "compte les notes des utilisateurs ayant jugés ces éléments.\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?export=view&id=1FjcxWD9IarWw3JAxhvTmagECHoZU-hjp' width=350></center>\n",
    "\n",
    "\n",
    "\n",
    "Deux types de filtrage collaboratif :\n",
    "\n",
    "- **Approche par voisinnage (memory-based)** : cette approche calcule la prédiction d'un item $i$ pour un utilisateur $x$ en se basant sur les plus proches voisins de $x$ (i.e. ceux dont l'ensemble de notations est similaire à l'ensemble des notation de $x$). \n",
    "\n",
    "- **Approche par modèles (model-based)** : cette approche cherche à predire le score d'un item $i$ pour un utilisateur $x$, sur la base des items qui sont similaires à $i$. Donc, l'estimation de la note pour l’élément se fait à partir des notes des éléments de $x$ similaires à $i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwhYbfx1i6Pk"
   },
   "source": [
    "## PARTIE 1 : Exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBPgyMOHi6Pl"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Note : </b> un exercice sur un fichier pdf séparé est disponible sur EDUNAO et Teams. Il vous permettra de réviser plus simplement les concepts du cours.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2RLGi6fhdKC"
   },
   "source": [
    "## PARTIE 2 : Applicaton au corpus MovieLens\n",
    "\n",
    "Dans cette partie nous travaillerons sur la base du corpus [MOVIELENS dataset](https://grouplens.org/datasets/movielens/) qui contient les jugements de films d'un ensemble d'utilisateurs ainsi que des informations sur les utilisateurs et sur les films. L'objectif de cette partie est de mettre en place un système de recommandation de films à partir de ce corpus. \n",
    "Il s'agira par exemple de pouvoir répondre à la question suivante : *quels sont les films pouvant plaire à une personne étant donné la connaissance sur cette personne (e.g. les autres films qu'elle a aimé ou les utilisateurs ressemblant à cette personne) ?* \n",
    "\n",
    "Pour ce travail, il est conseillé de travailler avec le [MovieLens 100K Dataset](https://grouplens.org/datasets/movielens/100k/) et de tester ensuite votre approche sur les datasets de  taille plus conséquente :\n",
    " + MovieLens 1M Dataset (1M de notes sur 4000 films par 6000 utilisateurs), disponible [ici](https://grouplens.org/datasets/movielens/1m/)\n",
    " + MovieLens 10M Dataset (10M de notes sur 10 000 films par 72000 utilisateurs, disponible [ici](https://grouplens.org/datasets/movielens/10m/)\n",
    " \n",
    "Pour répondre aux différentes questions nous allons faire appel à la bibliothque Pandas, numpy et matplotlib, que nous vous proposons d'installer en executant les cellules suivantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMWC2ZZQhdKH"
   },
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sgI-zYsr8Of"
   },
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPo6hJZpr8Og"
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4lwSQUDhdKT"
   },
   "source": [
    "### Etude du corpus\n",
    "\n",
    "Une des premières choses à faire est de prendre connaissance de ce corpus et de calculer quelques informations statistiques sur ce corpus. A l'aide des bibliothèques [pandas](https://pandas.pydata.org/), et [numpy](https://www.numpy.org),  répondez aux questions qui vont suivre concernant le corpus. Mais avant cela, nous allons introduire quelques éléments descriptifs utiles sur le corpus.\n",
    "\n",
    "Le corpus MOVIELENS est disponible [ici](https://grouplens.org/datasets/movielens/100k/) et mis à votre disposition dans le dossier Data.  Plus précisemment, ce corpus est constitué des fichiers suivants :\n",
    "\n",
    "+ Le fichier [u.data](./Data/ml-100k/u.data) : regroupe l'ensemble des données : 100000 notations par 943 utilisateurs sur 1682 items. Chaque utilisateur  a noté au moins 20 films.  Cette table contient:  \n",
    "\n",
    "               user id | item id | rating | timestamp.           \n",
    "          \n",
    "  les utilisateurs et les items sont numérotés à partir de  1 et les données sont aléatoirement ordonées.  \n",
    "  \n",
    "              \n",
    "+ Le fichier [u.user](./Data/ml-100k/u.user) : information démographique sur les utiliisateurs. Il contient: \n",
    "                         \n",
    "              user id | age | gender | occupation | zip code\n",
    "                         \n",
    "                            \n",
    "+ Le fichier [u.item](./Data/ml-100k/u.item) : contient les informations sur les items (films) : \n",
    "              \n",
    "              movie id | movie title | release date | video release date |\n",
    "              IMDb URL | unknown | Action | Adventure | Animation |\n",
    "              Children's | Comedy | Crime | Documentary | Drama | Fantasy |\n",
    "              Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |\n",
    "              Thriller | War | Western |\n",
    "              \n",
    "\n",
    "\n",
    "**Le code suivant permet d'extraire le contenu de ces fichiers.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgWnltoihdKU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#column headers for the dataset\n",
    "\n",
    "data_cols = ['user_id','item_id','rating','timestamp']\n",
    "\n",
    "#items' table\n",
    "\n",
    "item_cols = ['movie id','movie title','release date',\n",
    "'video release date','IMDb URL','unknown','Action',\n",
    "'Adventure','Animation','Childrens','Comedy','Crime',\n",
    "'Documentary','Drama','Fantasy','Film-Noir','Horror',\n",
    "'Musical','Mystery','Romance ','Sci-Fi','Thriller',\n",
    "'War' ,'Western']\n",
    "\n",
    "\n",
    "#users' table\n",
    "\n",
    "user_cols = ['user id','age','gender','occupation',\n",
    "'zip code']\n",
    "\n",
    "#importing the data files onto dataframes\n",
    "\n",
    "# Note: pour les presonnes sur Colab attention a mettre ./Archive_Lab7/Data/ au lieu de ./Data\n",
    "\n",
    "users = pd.read_csv('./Data/ml-100k/u.user', sep='|',names=user_cols, encoding='latin-1')\n",
    "item = pd.read_csv('./Data/ml-100k/u.item', sep='|',names=item_cols, encoding='latin-1')\n",
    "data = pd.read_csv('./Data/ml-100k/u.data', sep='\\t',names=data_cols, encoding='latin-1')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIoE9YzUhdKW"
   },
   "outputs": [],
   "source": [
    "#printing the head of these dataframes\n",
    "\n",
    "print(\"User information\")\n",
    "print(users.head()) # it will print only the head. To have the whole table remove .head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJ48ldcrhdKb"
   },
   "outputs": [],
   "source": [
    "print(\"Item information\")\n",
    "print(item.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kfdAS_cZhdKg"
   },
   "outputs": [],
   "source": [
    "print(\"Data information\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-kDWQ20hdKm"
   },
   "source": [
    "**1- Quel est le nombre de films et d'utilisateurs du corpus ?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncTDlieNhdKn"
   },
   "outputs": [],
   "source": [
    "# TO COMPLETE\n",
    "\n",
    "nb_users = # to complete\n",
    "nb_items = #to complete\n",
    "\n",
    "print(\"Number of users : \", nb_users)\n",
    "print(\"Number of movies : \", nb_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSaKUtz3i6Po"
   },
   "source": [
    "**Résultat attendu**\n",
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?export=view&id=1Uan38PEKTHBukWis-x5-uhBFs_qNupS6' width=300></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01a3RaTFhdKq"
   },
   "source": [
    "**2- Contruire la matrice d'utilité**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWnfb4lahdKs"
   },
   "outputs": [],
   "source": [
    "#Indication: pivot_table\n",
    "movie_matrix= #to complete\n",
    "movi_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1SHDA3Gi6Po"
   },
   "source": [
    "**Résultat attendu (here only the head)**\n",
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?export=view&id=1pHI972WSeIqM_Ua8vlT5VzARHTGarbQy' width=400></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9rMb7dzhdKv"
   },
   "source": [
    "**3- Quelle est la note moyenne de chaque film ?** \n",
    "\n",
    "Indication: on peut utiliser la fonction `groupby()` de Pandas. Quelques exemples [ici](https://www.tutorialspoint.com/python_pandas/python_pandas_groupby.htm). Sinon ne pas oublier de se reférer à la documentation officielle de Pandas [ici](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html?highlight=groupby#pandas.DataFrame.groupby). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibyYaFRdhdKv"
   },
   "outputs": [],
   "source": [
    "#Indication: mettre le résultat dans un DataFrame\n",
    "\n",
    "ratings = #To compelete\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3urgenf6i6Pp"
   },
   "source": [
    "**Résultat attendu(here only the head)**\n",
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?export=view&id=1KcS0EhKfWyMJOWn-FYTDDJpu8N1AIROt' width=100></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-k-fteghdKy"
   },
   "source": [
    "**4- Visualisation de la distribution des notes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKA-ykrwi6Pp"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warning: </b> if you did not install yet matplotlip, excute in a separate cell `!pip install matplotlib` \n",
    "</div>\n",
    "\n",
    "\n",
    "Remarque : `%matplotlib`configure la bibliothèque que vous allez utiliser pour dessiner le graphique. Elle effectue donc un certain nombre de traitements pour préparer l'affichage du graphique. Elle est souvent utilisée avec l'argument `inline`, qui indique que l'on va utiliser la bibliothèque intégrée à Notebook. \n",
    "\n",
    "Pour la fonction `hist()` des exemples [ici](https://www.science-emergence.com/Articles/Simple-histogramme-avec-matplotlib/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Op3WiLpIhdK2"
   },
   "outputs": [],
   "source": [
    "# Attention ces instructions ne peuvent être executées sans la réalisation de la question 3. \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ratings['rating'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLtrHok3i6Pp"
   },
   "source": [
    "**Résultat attendu**\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?export=view&id=1w6fsr9ExDO8fcJBvYylAA6Xc3zD2ySsp' width=300></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzQF3CRfhdK5"
   },
   "source": [
    " **5- Quel est le nombre de notes pour chaque film ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOGzS6TdhdK5"
   },
   "outputs": [],
   "source": [
    "ratings['number_of_ratings'] = # To complete\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opRAyWrBi6Pq"
   },
   "source": [
    "**Résultat attendu (head only)**\n",
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?export=view&id=1OciH_atHuyuWfNInKMN4tZpxnAwwByPR' width=300></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLIEyLvui6Pq"
   },
   "source": [
    "**6- Visualiser le nombre de notes pour chaque film (comme nous l'avons fait à la question 4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3tIYE3li6Pq"
   },
   "outputs": [],
   "source": [
    "# To complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3Rcdr_ghdK8"
   },
   "source": [
    "## Système de recommandation\n",
    "\n",
    "### Préparation de l'évaluation\n",
    "\n",
    "Une première phase dans le problème de prédiction de la recommandation est de préparer l'étape d'évaluation de votre système de recommandationn en séparant l'ensemble de données en  un ensemble de test et en un ensemble d'apprentissage. \n",
    "\n",
    "<center><img src='https://drive.google.com/uc?export=view&id=1i6nY-QOBnZAyWr5dlQraDHHToZLbgqU7' width=300></center>\n",
    "\n",
    "\n",
    "- L'ensemble d'apprentissage sera utilisé pour construire la matrice d'utilité, calculer le score de similarité et faire la prédiction. \n",
    "- L'ensemble de test sera utilisé dans la phase d'évaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMVn0F3si6Pq"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warning: </b> Avant de commencer executer la cellule suivante: \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XI91YaHkr8Ox"
   },
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUqAB_7fi6Pr"
   },
   "source": [
    "**Séparons nos données `data` en deux sous ensembles : un ensemble d'apprentissage et un ensemble de test. On prendra par exemple une taille d'ensemble de test de $0.25$**.\n",
    "\n",
    "Indication : on fera appel à la fonction `model_selection()` dont la documentation se trouve [ici](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VEuuoQ4hdK_"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection \n",
    "\n",
    "train_data, test_data = # TO COMPLETE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qj_aqGfhi6Pr"
   },
   "outputs": [],
   "source": [
    "print(\"Taindata\\n\")\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPSr9WRTi6Pr"
   },
   "outputs": [],
   "source": [
    "print(\"Testdata\\n\")\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igQk5XmfhdLC"
   },
   "source": [
    "### Approche par voisinage (user-item, Memory-based)\n",
    "\n",
    "Il s'agit d'implémenter la méthode de filtrage collaboratif par voisinage **user-item** en suivant les étapes ci-dessous.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EK9zAAlbhdLD"
   },
   "source": [
    "### Etape 1 : \n",
    "\n",
    "**a- Construire la matrice user-item à partir de l'ensemble des données. (Cela vous permettra de visualiser le contenu des données qui sont considérées pour l'apprentissage.)** \n",
    "\n",
    "Attention : on utilisera la matrice `train_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfXbO3fAhdLE"
   },
   "outputs": [],
   "source": [
    "#indication: utiliser pivot_table\n",
    "\n",
    "movie_matrix = # TO COMPLETE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8o_kqj4i6Ps"
   },
   "source": [
    "**b- Constuire la matrice d'utilité contenant que les notes ou les évaluations des différents items. On appelera cette matrice `train_data_matrix`. C'est cette matrice qui sera utilisée par la suite pour faire nos calculs de similarités et de prédictions.**\n",
    "\n",
    "\n",
    "Attention : on utilisera la matrice `train_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqsdKPvoi6Ps"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data_matrix= #To complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffXEJyQni6Ps"
   },
   "source": [
    "\n",
    "**Expected result**\n",
    "\n",
    "<img src=\"./Figures/result_b.png\" width=\"150\" height=\"150\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfhU7P2mhdLH"
   },
   "source": [
    "**c- Construire la matrice de test contenant que les évaluation (ou les notations) des différents items. On appelera cette matrice `test_data_matrix`. C'est cette matrice qui sera utilisée par la suite dans la phase d'évaluation**. \n",
    "\n",
    "Attention : on utilisera la matrice `test_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZZhStbshdLH"
   },
   "outputs": [],
   "source": [
    "test_data_matrix =# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMOzS5Ypi6Ps"
   },
   "source": [
    "\n",
    "**Expected result**\n",
    "\n",
    "<img src=\"./Figures/result_c.png\" width=\"150\" height=\"150\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUGDWIPZhdLK"
   },
   "source": [
    "### Etape 2 : Construire et Calculer la matrice de similarité entre utilisateurs. \n",
    "\n",
    "On utilisera dans un premier temps la mesure **cosinus** : \n",
    "\n",
    "$$sim(x,y) = cos (r_x,r_y) = \\frac{r_x.r_y}{||r_x||.||r_y||}$$\n",
    "\n",
    "\n",
    "(on pourra utiliser pour cela la méthode **pairwise\\_distances** de scikit-learn documentée [ici]( https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vs-WyEythdLL"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "user_similarity= # TO COMPLETE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b5lbZm4i6Pt"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Note : </b> vous pouvez utiliser une autre mesure de similarité comme celle de Pearons (voir plus bas). Notre conseil est de terminer en premier le travail avec la mesure cosinus. Une fois la fonction de prédiction mise en place et que celle-ci fonctionne vous pouvez revenir pour écrire la\n",
    "    fonction de similarité avec Pearson et la tester ensuite avec la fonction de prédiction. Donc on peut passer à l'étape 3. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oILyUMfohdLN"
   },
   "source": [
    "**La mesure de corrélation de Pearson** \n",
    "\n",
    "étant donnés deux utilisateurs $x$ et $y$ :\n",
    "\n",
    "$$ sim(x,y) = \\frac{\\sum_{s \\in S_{xy}} (r_{xs} - \\overline{r_x})(r_{ys} - \\overline{r_y}) }{ \\sqrt{\\sum_{s \\in S_{xy}} (r_{xs} - \\overline{r_x})^2}   \\sqrt{\\sum_{s \\in S_{xy}} (r_{ys} - \\overline{r_y})^2}  }$$\n",
    "\n",
    "avec $\\overline{r_y}$ et  $\\overline{r_x}$ la notation moyenne de $x$ et $y$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZ4CF-PehdLP"
   },
   "source": [
    "**Remarque**: `pearsonr()` da la bibliothèque `stats` retourne un tuple composé du coefficient de corrélation et de la p-valeur:\n",
    "\n",
    "Le coefficient de corrélation peut varier de -1 à +1. L'hypothèse nulle est que les deux variables ne sont pas corrélées. La valeur de $p$ est un nombre compris entre zéro et celui qui représente la probabilité que vos données se serait produites si l'hypothèse nulle était vraie.\n",
    "Pour plus de détails, voir http://www.eecs.qmul.ac.uk/~norman/blog_articles/p_values.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7Y-yzlghdLP",
    "outputId": "fe33639b-2a44-423e-879d-a81cb5256306"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8660254037844386"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exemple\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([0, 0, 0, 1, 1, 1, 1])\n",
    "b = np.arange(7)\n",
    "stats.pearsonr(a, b)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6QZtYdIhdLV"
   },
   "source": [
    "### Etape 3 :  Construction de la matrice de prédictions en utilisant la formule suivante.\n",
    "\n",
    "La note de l'utilisateur $x$ sur l'élément $i$ est calculée comme suit :\n",
    "\n",
    "$$ r_{xi} = \\overline{r_x} + \\frac{\\sum_{y \\in N} sim(x,y) (r_{yi} -\\overline{r_y})}{\\sum_{y \\in N} | sim(x,y)|}$$\n",
    "\n",
    "\n",
    "Avec: $\\overline{r}_x$ la note moyenne de l'utilisateur $x$,  $\\overline{r}_y$ la note moyenne de l'utilisateur $y$ et $r_{yi}$ la note de l'utilisateur $y$ qui a jugé $i$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OA9_3ZAWi6Pt"
   },
   "source": [
    "**Ecrire la fonction `predict(ratings, similarity, type='user')` qui prendra en entrée les évaluations, la matrice de similarités et un troisième argument qui est `type='user'`. Il est intéressant de le considérer pour pourvoir réutiliser la fonction dans l'approche par modèles en mettant `type='item'`.** \n",
    "\n",
    "**Encore une fois vous pouvez écrire simplement la fonction `predict(ratings, similarity)` qui retournera à la fin la matrice de prédictions des différents items pour les différents utilisateurs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DH0EDZJYhdLW"
   },
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    \n",
    "    # TO COMPLETE\n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gceAT5NLi6Pu"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "user_prediction = predict(train_data_matrix, user_similarity, type='user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzA-Yir1hdLY"
   },
   "source": [
    "### Etape 4 :  Evaluer votre prédiction avec la mesure RMSE (Root Mean Squared Error).\n",
    "\n",
    "\n",
    "$$\\sqrt{\\frac{1}{n} \\sum_{xi} (r_{xi} - r_{xi}^{*})^{2}}$$\n",
    "où, $r_{xi}^{*}$ correspond à la valeur prédite pour $r_{xi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAf-iPZhhdLZ"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse(prediction, ground_truth):\n",
    "    #To compelte\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shzoTsuRi6Pw"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmR71ap6i6Pw"
   },
   "source": [
    "## Approche par modèles : **item-item**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go2OVe-ui6Pw"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Conseil : </b>  à faire une fois la partie memory-based réalisée. \n",
    "</div>\n",
    "\n",
    "#### **Faire le même travail avec l'approche item-item. Il est possible  de réutiliser les fonctions implémentées précédemment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9eGjH26i6Px"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IJpleJ7yeyJ"
   },
   "source": [
    "## PARTIE 3 (Optionnelle): Pour aller plus loin... \n",
    "\n",
    "Pour aller plus loin et pour les curieux vous pouvez regarder ce [cours/Lab](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/recommendation-systems/recommendation-systems.ipynb?utm_source=ss-recommendation-systems&utm_campaign=colab-external&utm_medium=referral&utm_content=recommendation-systems#scrollTo=9EjQt_o9Xf_L) qui aborde la recommandation avec la technique de factorisation de matrices (matrix factorization model -- non abodée dans le cours) et donc l'utilisation de Tensorflow. \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_7_Recommandation-Students.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
